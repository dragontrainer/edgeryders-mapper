# This program accepts a list of users and a list of comments as CSV files and builds the associated graph.
# Adding clustering coefficient

# UNICODE: "u'Something"
from __future__ import division


from tulip import *
import json
import csv
import datetime
import time
import sys
sys.path.append ('/Users/albertocottica/Dropbox/PhD/MyPhDcode/')
from tulip2networkx import *
from modularity import *



# define the main method

# Powered by Python 2.7

# To cancel the modifications performed by the script
# on the current graph, click on the undo button.

# Some useful keyboards shortcuts : 
#   * Ctrl + D : comment selected lines.
#   * Ctrl + Shift + D  : uncomment selected lines.
#   * Ctrl + I : indent selected lines.
#   * Ctrl + Shift + I  : unindent selected lines.
#   * Ctrl + Return  : run script.
#   * Ctrl + F  : find selected text.
#   * Ctrl + R  : replace selected text.
#   * Ctrl + Space  : show auto-completion dialog.

# the updateVisualization(centerViews = True) function can be called
# during script execution to update the opened views

# the pauseScript() function can be called to pause the script execution.
# To resume the script execution, you will have to click on the "Run script " button.

# the runGraphScript(scriptFile, graph) function can be called to launch another edited script on a tlp.Graph object.
# The scriptFile parameter defines the script name to call (in the form [a-zA-Z0-9_]+.py)

# the main(graph) function must be defined 
# to run the script on the current graph

# GM - creating the userlis and commentlist as local variables
# GM - is not that handy (at least for debugging)
# GM - we'll turn them into global variables and pass them on to the main method

def main(graph): 
    viewBorderColor =  graph.getColorProperty("viewBorderColor")
    viewBorderWidth =  graph.getDoubleProperty("viewBorderWidth")
    viewColor =  graph.getColorProperty("viewColor")
    viewFont =  graph.getStringProperty("viewFont")
    viewFontSize =  graph.getIntegerProperty("viewFontSize")
    viewLabel =  graph.getStringProperty("viewLabel")
    viewLabelColor =  graph.getColorProperty("viewLabelColor")
    viewLabelPosition =  graph.getIntegerProperty("viewLabelPosition")
    viewLayout =  graph.getLayoutProperty("viewLayout")
    viewMetaGraph =  graph.getGraphProperty("viewMetaGraph")
    viewRotation =  graph.getDoubleProperty("viewRotation")
    viewSelection =  graph.getBooleanProperty("viewSelection")
    viewShape =  graph.getIntegerProperty("viewShape")
    viewSize =  graph.getSizeProperty("viewSize")
    viewSrcAnchorShape =  graph.getIntegerProperty("viewSrcAnchorShape")
    viewSrcAnchorSize =  graph.getSizeProperty("viewSrcAnchorSize")
    viewTexture =  graph.getStringProperty("viewTexture")
    viewTgtAnchorShape =  graph.getIntegerProperty("viewTgtAnchorShape")
    viewTgtAnchorSize =  graph.getSizeProperty("viewTgtAnchorSize")

    for n in graph.getNodes():
        print n


    # Start reading the files
    dirPath = '/Users/albertocottica/Dropbox/PhD/MyPhDdata/Extraction 2012-12-05-1623/'

    # Here's the output file: REMEMBER TO CHANGE THIS
    # to_filename = dirPath + 'output.csv'
    # to_file = open(to_filename, 'w')

    # load comments
    comments_filename = dirPath + 'commentslist.csv'
    comments_reader = csv.DictReader(open(comments_filename, 'rb'), delimiter=',')
    commentslist = []
    for line in comments_reader:
        commentslist.append(line)

    # load posts
    posts_filename = dirPath + 'postslist.csv' 
    posts_reader = csv.DictReader(open(posts_filename, 'rb'), delimiter=',')
    postslist = []
    for line in posts_reader:
          postslist.append(line)
    

    # load users
    users_filename = dirPath + 'userlist_w_xusers.csv' 
    users_reader = csv.DictReader(open(users_filename, 'rb'), delimiter=',')
    userlist = []
    for line in users_reader:
        userlist.append(line)

    # assign the time interval step in UNIX time: 4 weeks == 2419200

    timestep = int(2419200/4) #corresponds to ONE week
    time_0 = 1321228800 # corresponds to November 14th 2011
    time_final = 1355529600
    

    # We build the graph


    # graph = tlp.newgraph() # when executing from within Tulip GUI, you omit this. The empty graph is loaded by default.

    # GM - I am unsure what this instruction does
    # GM - I'll assume we are working with a brand new, empty,
    # GM - graph so we don't need to invoke this method
    # graph = graph.clear()

    print 'Building graph...'

    # create the properties of nodes 
    my_ID_var = graph.getIntegerProperty('user_id')
    user_name = graph.getStringProperty('user_name')
    is_team = graph.getBooleanProperty('team')
    dateProperty = graph.getDoubleProperty('timestamp')
    # dateProperty stores the account creation date of node (user)
    # dateProperty stores the publication date of a comment (edge)
    effortProperty = graph.getDoubleProperty('effort')
    # effortProperty stores the length of the comment.
    topicProperty = graph.getStringProperty('topic')
    briefIDProperty = graph.getStringProperty('brief_id')
    #topicProperty stores the Edgeryders campaign under which the comment is nested.
    #briefIDProperty stores the Edgeryders mission brief under which the comment is nested.
    weightProperty = graph.getDoubleProperty('weight')
    # weightProperty is for deparallelized, weighted subgraphs.
    # weightProperty is then initialized to 1 for all edges.

    # create nodes and populate their properties.
    for u in range (len (userlist)):
        n = graph.addNode()
        my_ID_var[n] = int (userlist[u]['user_id']) # the name my_ID_var is to distinguish it from Tulip's internally assigned node ID.
        # user_name[n] = userlist[u]['user_id'] # this property runs into unicode errors
        is_team[n] = bool (int(userlist[u]['team'])) #this property loads as always true! 
        dateProperty[n] = time.mktime(time.strptime(userlist[u]['joindate'], '%Y-%m-%d'))
        #print ('Node ' + str(n) + ' created, with id ', my_ID_var[n])
        #print (str(u) + ' nodes created.')

    # now create edges. Loop over comments:
    
    for comment in commentslist:
        # comment

        # GM - the following line throws an exception 'KeyError'
        # GM - and says the 'nid' key does not exist
        #print comment

        if not comment['author_id'] == '0':
            if not comment['target_id'] == '0': # we weed out comments that don't refer to valid users
    
                sid = int(comment['author_id'])
                tid = int(comment['target_id'])
                sNode = findNodeById(sid, graph, my_ID_var) 
                tNode = findNodeById(tid, graph, my_ID_var)

                try:
                    edge = graph.addEdge(sNode, tNode)
                except TypeError:
                    print(sid, sNode)
                    print(tid, tNode)
                    print '***'
                    pass

            # add property values to this edge
            # ...
                dateProperty[edge] = int(comment['timestamp'])
                effortProperty[edge] = int(comment['effort'])
                is_team[edge] = int(comment['author_team'])
                topicProperty[edge] = comment['topic']
                briefIDProperty[edge] = comment['brief_id']
                weightProperty[edge] = 1

    # before creating any subgraph, store the nodes and edges of the root graph
    # into Python objects

    mainNodes = [n for n in graph.getNodes()]
    mainEdges = [e for e in graph.getEdges()]
    
    tlp.saveGraph(graph, (dirPath + 'To Guy/ERgraph_no_subgraphs.tlp'))


    # create subgraphs

    print 'Building subgraphs...'

    for t in range(time_0, time_final, timestep):
        # build graph with items having timestamp <= t
        sg = graph.addSubGraph()
        sg.setName(str(t))
        for n in graph.getNodes():
            if dateProperty.getNodeValue(n) <= t:
                sg.addNode(n)
        for e in graph.getEdges():
            if dateProperty.getEdgeValue(e) <= t:
                sg.addEdge(e)


## Moving this over to the deparallelized graph    

##    # compute node-specific network properties
##
##    nodeMetricNames = ['Cluster', 'K-Cores', 'PageRank']#, 'Eccentricity'] # add more ...
##    # Betweenness Centrality is computed below from deparallelized graphs
##    #nodeMetricProperties = {}
##    for sg in graph.getSubGraphs():
##
##        # compute subgraph metrics and store as local properties
##        for metricName in nodeMetricNames:
##            resultProperty = sg.getLocalDoubleProperty(metricName)
##            dataSet = tlp.getDefaultPluginParameters(metricName, sg)
##            # WARNING THE PROPERTY IS OVERWRITTEN HERE THROUGH DIFFERENT SUBGRAPH
##            #nodeMetricProperties[metricName] = resultProperty
##            sg.applyDoubleAlgorithm(metricName, resultProperty, dataSet)
            
    # tlp.saveGraph(graph, (dirPath + "/To Guy/ERgraph_w_subgraphs.tlp"))

    # create deparallelized subgraphs

    print 'Creating deparallelized subgraphs...'

    for t in range(time_0, time_final, timestep):
        # add nodes. This can be done in one pass.
        dpsg = graph.addSubGraph()
        dpsg.setName('dp_' + str(t))
        print ('Now building subgraph ' + str (dpsg.getName()))
        for n in graph.getNodes():
            if dateProperty.getNodeValue(n) <= t:
                dpsg.addNode(n)

        # to add edges, iterate over nodes in the newly built subgraph and look for unique neighbors.

        for n in dpsg.getNodes():
            dictOutNeighbors = {}
            for e in graph.getOutEdges(n): # this iteration happens over the MAIN graph.
                if e in mainEdges: # does this edge correspond to an actual comment?

                    if dateProperty.getEdgeValue(e) <= int(t): # is the node old enough to be in this dp-subgraph?

                        neighbor = graph.target(e) # if YES then let this be the target of this edge
                        if neighbor not in dictOutNeighbors: # is neighbor already in the dict of targets of edges?
                            dictOutNeighbors[neighbor] = [] # if NO, then create a field for that node. Assign an empty list as its value
                            # sc = graph.source(e) # this is the source node of this edge - should always be n!
                            # tg = graph.target(e) # this is the target - should always be neighbor!
                            newEdge = dpsg.addEdge(n,neighbor) # add a new edge to the graph with the same source and target as the edge in mainEdges. notice: add new edge, not reuse e. a
                            # now populate the properties of this edge.
                            weightProperty[newEdge] = 1 # there is no other edge with the same source and target, so it has weight (Count) = 1
                            effortProperty[newEdge] = effortProperty[e]  # there is no other edge with the same source and target, so it has effort = the effort of e
                            
                        else: # if YES, the target of e is already in dictOutNeighbors:
                            # iterate over OutEdges already added to the new subgraph and look for the one
                            # with the same target as e.
                            for e2 in dpsg.getOutEdges(n):
                                if neighbor == dpsg.target(e2):
                                    weightProperty[e2] += 1
                                    effortProperty[e2] = effortProperty[e2] + effortProperty[e]


    tlp.saveGraph(graph, dirPath+"/To_Guy/ERgraph_w_dp_subgraphs_try.tlp")

##    # compute node-specific network properties

    nodeMetricNames = ['Cluster', 'K-Cores', 'Page Rank']#, 'Eccentricity'] # add more ...
    # Betweenness Centrality is computed below from deparallelized graphs
    #nodeMetricProperties = {}
    for dpsg in graph.getSubGraphs():

        # compute subgraph metrics and store as local properties
        for metricName in nodeMetricNames:
            resultProperty = dpsg.getLocalDoubleProperty(metricName)
            dataSet = tlp.getDefaultPluginParameters(metricName, dpsg)
            # WARNING THE PROPERTY IS OVERWRITTEN HERE THROUGH DIFFERENT SUBGRAPH
            #nodeMetricProperties[metricName] = resultProperty
            dpsg.applyDoubleAlgorithm(metricName, resultProperty, dataSet)

        # compute Betweenness centrality using networkx

        betweennessCentralityCount = dpsg.getDoubleProperty('betweennessCentralityCount') #initialize the properties
        betweennessCentralityEffort = dpsg.getDoubleProperty('betweennessCentralityEffort')
        nxOCount = NetworkxOperation (dpsg, weightProperty) # converts to networkx
        nxOEffort = NetworkxOperation (dpsg, effortProperty)
        #...and computes the centrality
        # the objects returned are dictionaries {<tulipNode>:centrality}
        centMapCount = nxOCount.compute_centrality()
        centMapEffort = nxOEffort.compute_centrality()

        for n in dpsg.getNodes():
            betweennessCentralityCount[n] = centMapCount[n]
            betweennessCentralityEffort[n] = centMapEffort[n]


        # compute edge density
        numEdges = int(dpsg.numberOfEdges())
        numNodes = int(dpsg.numberOfNodes())
        density = numEdges/(numNodes * (numNodes - 1))

        # compute (global) clustering coefficient

        avgClusteringCoefficient = 0
        cc = dpsg.getDoubleProperty('Cluster')
        for n in dpsg.getNodes():
            avgClusteringCoefficient = avgClusteringCoefficient + cc[n]/numNodes
            
        
        
        # compute Louvain modularity using both count and effort
        weightPropertyCount = dpsg.getDoubleProperty ('weight')
        avgLouvainCount = averageLouvain20 (dpsg, weightPropertyCount)
        weightPropertyEffort = dpsg.getDoubleProperty('effort')
        avgLouvainEffort = averageLouvain20 (dpsg, weightPropertyEffort)
        
        
        # for easy printing to file, store global properties as node properties.
        # all nodes in the same subgraph are assigned the same values for each global property.
        # initialize
        graphDensity = dpsg.getDoubleProperty ('graphDensity')
        modularityCount = dpsg.getDoubleProperty ('modularityCount')
        modularityEffort = dpsg.getDoubleProperty ('modularityEffort')
        averageClusteringCoefficient = dpsg.getDoubleProperty ('averageClusteringCoefficient')
        
        for n in dpsg.getNodes():
            graphDensity [n] = density
            modularityCount [n] = avgLouvainCount
            modularityEffort [n] = avgLouvainEffort
            averageClusteringCoefficient [n] = avgClusteringCoefficient
        # also store activity data as node properties,
        # so that the Tulip graph stores all the relevant information

    tlp.saveGraph(graph, dirPath+"/To_Guy/ERgraph_w_dp_subgraphs.tlp")

    # print the csv file

    print 'Writing the output to file...'
    topics = ['01 - Bootcamp', '02 - Making a living', '03 - We, the people', '04 - Caring for commons', '05 - Learning',
                  '06 - Living together', '07 -Finale', '08 - Resilience', '00 - Undefined']
    
    # print headers to csv file
    csvfile = open(dirPath + 'subGraphsTabData7.csv', 'w')
    activityMetricNames = []
    for topic in topics:
        activityMetricNames.append('NPosts in ' + topic)
        activityMetricNames.append('EPosts in ' + topic)
    for topic in topics:
        activityMetricNames.append('NComms written in ' + topic)
        activityMetricNames.append('EComms written in ' + topic)
    for topic in topics:
        activityMetricNames.append('NTeam comms received in ' + topic)
        activityMetricNames.append('ETeam comms received in ' + topic)
    for topic in topics:
        activityMetricNames.append('NComms received in ' + topic)
        activityMetricNames.append('EComms received in ' + topic)

    neighboringMetricNames = ['Indegree','Outdegree']
    dpGraphMetricNames = ['betweennessCentralityCount', 'betweennessCentralityEffort', 'graphDensity', 'modularityCount', 'modularityEffort', 'averageClusteringCoefficient'] 


    fieldNames = ['node id', 'is_team', 'creation date', 'timestamp'] + activityMetricNames + nodeMetricNames + neighboringMetricNames + dpGraphMetricNames
    csvwriter = csv.DictWriter(csvfile, fieldNames, delimiter = ',')
    csvwriter.writerow(dict((fn,fn) for fn in fieldNames))

    # node id, creation y/n, time considered, number of posts and effort of posts written per each topic, number and effort
    # of comments received per each topic, number and effort team of comments received per each topic, 
    for n in graph.getNodes():
        user_i_time_t = {} # the accumulator for the row
        user_i_time_t['node id'] = str(my_ID_var[n])
        print 'Now processing user ', str(my_ID_var[n])
        user_i_time_t['creation date'] = (str(dateProperty[n]))
        user_i_time_t['is_team'] = int(is_team[n])

        # iterate over time periods, grabbing the relevant subgraph for each one
        for t in range(time_0, time_final, timestep):
            sg = graph.getSubGraph(str(t))

            user_i_time_t['timestamp'] = (str(t))
            # print 'processing subgraph: ', str(t)
            
            # Initialize accumulators:
            user_i_time_t['Indegree'] = 0
            user_i_time_t['Outdegree'] = 0

            for metric in activityMetricNames:
                user_i_time_t[metric] = 0

            for metric in nodeMetricNames:
                user_i_time_t[metric] = 0

            if not sg.isElement(n):
                # assign default values
                csvwriter.writerow(user_i_time_t)
                continue

            for metric in nodeMetricNames:
                metricProperty = sg.getLocalDoubleProperty(metric)
                user_i_time_t[metric] = metricProperty[n]
            
            # fill in the posts written by this user at this time.
            for x in range (len(postslist)):
                # 14 Oct 2011 - 16:55 %d %b %Y - %H:%M
                if str(postslist[x]['author_id']) == str(my_ID_var[n]) and \
                   (time.mktime(time.strptime(postslist[x]['date'], "%d %b %Y - %H:%M")) < t) and \
                   (time.mktime(time.strptime(postslist[x]['date'], "%d %b %Y - %H:%M")) >= t - timestep):
                    for topic in topics:
                        if postslist[x]['topic'] == topic:
                            user_i_time_t['NPosts in ' + topic] += 1
                            user_i_time_t['EPosts in ' + topic] += int(postslist[x]['effort'])


            dictInNeighbors = {}
            for e in sg.getInEdges(n):
                # grabbing unique in neighbors
                neighbor = sg.source(e)
                if neighbor not in dictInNeighbors:
                    dictInNeighbors[neighbor] = []
                dictInNeighbors[neighbor].append(e)
                # counting comments and effort to our user

                eTimestamp = dateProperty[e]
                eTopic = topicProperty[e]
                effort = int(effortProperty[e])
                #print "timestamp: ", dateProperty[e], "/", (t - timestep), " >> ", (dateProperty[e] >= (t - timestep))
                if dateProperty[e] >= (t - timestep):
                    # this is to avoid multiple counting of comments left in previous periods (edges endure).
                    if is_team[e]:
                        user_i_time_t['NTeam comms received in ' + eTopic] += 1
                        user_i_time_t['ETeam comms received in ' + eTopic] += effort
                    else:
                        user_i_time_t['NComms received in ' + eTopic] += 1
                        user_i_time_t['EComms received in ' + eTopic] += effort


            dictOutNeighbors = {}
            for e in sg.getOutEdges(n):
                # grabbing unique out neighbors
                neighbor = sg.target(e)
                if neighbor not in dictOutNeighbors:
                    dictOutNeighbors[neighbor] = []
                dictOutNeighbors[neighbor].append(e)

                # counting comments and effort from our user
                if dateProperty[e] > (int(t) - timestep) and dateProperty[e] <= int(t): # not sure about this
                    eTopic = topicProperty[e]
                    effort = int(effortProperty[e])
                    user_i_time_t['NComms written in ' + eTopic] += 1
                    user_i_time_t['EComms written in ' + eTopic] += effort



            user_i_time_t['Indegree'] = len(dictInNeighbors)
            user_i_time_t['Outdegree'] = len(dictOutNeighbors)

        
            # now metrics pertaining to the deparallelized graphs (dpGraphMetrics). First, grab the deparallelized graph.
            dpsg = graph.getSubGraph('dp_' + str(t))

            for metric in dpGraphMetricNames:
                metricProperty = dpsg.getDoubleProperty(metric)
                user_i_time_t[metric] = metricProperty[n]
                
                           
            csvwriter.writerow(user_i_time_t)



    csvfile.close()
    print ("The end")
    


# define the non-main function(s) needed:


def findNodeById(id, graph, idProperty):
    '''
      finds a node if it exists / return None otherwise. 
      '''
    for n in graph.getNodes():
        if idProperty[n] == id:
            return n
    return None
    


def drupal_to_unix_time(datestring):
    '''
    str => int 
    returns the Unix time corresponding to datestring of the type '14 Oct 2011 - 16:55'
    >>> drupal_to_unixtime('14 Oct 2011 - 16:55')
    requires time module
    XXXXXXXXXXXX
    >>>
    '''
    import time
    import datetime

    # convert the month, given in letter, into an int:

    # convert the month, given in letter, into an int:
    monthint = 666

    if datestring [-16:-13] == 'Jan':
        monthint = 1
    elif datestring [-16:-13] == 'Feb':
        monthint = 2
    elif datestring [-16:-13] == 'Mar':
        monthint = 3
    elif datestring [-16:-13] == 'Apr':
        monthint = 4
    elif datestring [-16:-13] == 'May':
        monthint = 5
    elif datestring [-16:-13] == 'Jun':
        monthint = 6
    elif datestring [-16:-13] == 'Jul':
        monthint = 7
    elif datestring [-16:-13] == 'Aug':
        monthint = 8
    elif datestring [-16:-13] == 'Sep':
        monthint = 9
    elif datestring [-16:-13] == 'Oct':
        monthint = 10
    elif datestring [-16:-13] == 'Nov':
        monthint = 11
    elif datestring [-16:-13] == 'Dec':
        monthint = 12
    else:
        monthint = 0

    # convert the string to a string in a time tuple: (YYYY, MM, DD, HH, MM, SS, 0, 0, 0)
    datetuple = (int(datestring[-12:-8]), monthint, int(datestring[:-17]), int(datestring[-5:-3]), int(datestring[-2:]), 0, 0, 0, 0)
    # now use time to convert the time tuple into UTC
    return (int(time.mktime(datetuple)))


graph = tlp.newGraph()
main(graph)

def display(node, graph):
    print('node tulip id ', node.id)
    uid = graph.getIntegerProperty('user_id')
    print('user_id ',  uid[node])
    isteam = graph.getBooleanProperty('is_team')
    print('is team ',  isteam[node])
    date = graph.getIntegerProperty('timestamp')
    print ('creation date ', date[node])
    
